{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVxjI+n4U6tP8AuAuqc0cL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luoshaoyang/cs224w_final_proj/blob/main/Colab_FinalProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Visible Masking/Watermark Removal with Graph Neural Network"
      ],
      "metadata": {
        "id": "fPkn6dGvbTT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "FOLDERNAME = 'CS224WFinalProj/'\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jguCIZVQzYGd",
        "outputId": "4f1c746a-18d3-4bc5-813b-63879c121c76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CS224WFinalProj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "* Import Libraries\n",
        "* Handy Functions<br>\n",
        " 1. loadImage\n",
        " 2. image2NN\n",
        " 3. NN2Image\n",
        " 4. plotImage\n",
        " 5. image2GrayScale\n",
        " 6. image2Binary\n",
        " 7. overlayerImg\n",
        " 8. overlayImg1OverImg2\n"
      ],
      "metadata": {
        "id": "ckOOSgd9bXP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o4FTTICIbQjI"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions\n",
        "def loadImage(path,plotImg=True,gray_scale=False):\n",
        "  #####################################################\n",
        "  #Read in image path and returns an image\n",
        "  #####################################################\n",
        "  image = cv2.imread(path,flag=int(gray_scale))\n",
        "  image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY if gray_scale else cv2.COLOR_BGR2RGB)  \n",
        "  if plotImg:\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "  return image\n",
        "\n",
        "def image2Tensor(img,gray_scale=True):\n",
        "  #####################################################\n",
        "  #Read in image, and return tensor of the image\n",
        "  #  more interesting reading: https://towardsdatascience.com/image-read-and-resize-with-opencv-tensorflow-and-pil-3e0f29b992be\n",
        "  #####################################################\n",
        "  # convert BGR image to RGB image\n",
        "  img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY if gray_scale else cv2.COLOR_BGR2RGB)\n",
        "  transform = transforms.Compose([transforms.ToTensor()])\n",
        "  img_tensor = transform(img)\n",
        "  return img_tensor\n",
        "\n",
        "def Tensor2Image(img_tensor,dim_order=None,gray_scale=True,plotImg=True):\n",
        "  #####################################################\n",
        "  #Read in tensor, and return plotable image\n",
        "  #####################################################\n",
        "  img = img_tensor.numpy()\n",
        "  if dim_order:\n",
        "    img = np.transpose(img,order)\n",
        "  img = cvtColor(img,cv2.COLOR_BGR2GRAY if gray_scale else cv2.COLOR_BGR2RGB)\n",
        "  if plotImg:\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "  return img\n",
        "\n",
        "def plotImg(image):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def image2GrayScale(image):\n",
        "  img = cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  return img\n",
        "\n",
        "def image2Binary(image):\n",
        "  img = image2GrayScale(image)\n",
        "  img = np.round(img)\n",
        "  return img\n",
        "\n",
        "def overlayerImg(size,rgb):\n",
        "  #####################################################\n",
        "  #Create a box overlay image that could go above the license plate\n",
        "  #  rgb being a vector of shape (,3); size being a vector of shape (row,col,3)\n",
        "  #####################################################\n",
        "  img = np.ndarray([[[rgb[0]]*size.shape[0]]*size.shape[1],\n",
        "                    [[rgb[1]]*size.shape[0]]*size.shape[1],\n",
        "                    [[rgb[2]]*size.shape[0]]*size.shape[1]])\n",
        "  return img\n",
        "\n",
        "def overlayImg1OverImg2(img1,img2):\n",
        "  #####################################################\n",
        "  #Overlay the box image (img1) above the license plate(img2)\n",
        "  #  center the images at the same place\n",
        "  #####################################################\n",
        "  img = img2.copy()\n",
        "  y_lower = np.round(img.shape[0]/2)-np.round(img1.shape[0]/2)\n",
        "  y_upper = y_lower+img1.shape[0]# (y_lower,y_upper]\n",
        "  img[y_lower:y_upper,:,:] = img1\n",
        "  return img"
      ],
      "metadata": {
        "id": "WiZWACyafvDN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing\n",
        "* Read in the datasets\n",
        "* Create masked/watermarked datasets\n",
        "* Split for training and testing"
      ],
      "metadata": {
        "id": "KSegHW9gbdFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DataSet\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "idx=0#for image 0 in training\n",
        "path = os.path.join('../data', train.loc[idx, 'Label'], train.loc[idx, 'Image'])\n",
        "loadImage(path)"
      ],
      "metadata": {
        "id": "uGSgKkRgbhyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create masked datasets"
      ],
      "metadata": {
        "id": "OJEeODGKf3Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for training and testing"
      ],
      "metadata": {
        "id": "KD37zNigf7N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Build\n",
        "* Learn GNN embedding\n",
        "* Apply GCN to predict<br>\n",
        "  1. GCN training\n",
        "  2. Accuracy measurement\n",
        "* Apply label propagation to predict<br>\n",
        "  1. Edge weight training\n",
        "  2. propagation iteration\n",
        "  3. Accuracy measurement"
      ],
      "metadata": {
        "id": "SHatHSDEdhZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN embedding learning"
      ],
      "metadata": {
        "id": "0YpcNMtrgNpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GCN Model"
      ],
      "metadata": {
        "id": "YgsPnH7GgQpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Propagation\n",
        "#####################################\n",
        "#prepare edge_weight and nn graph\n",
        "#- dict edge_weights = {(from_node_id,to_node_id):weight}\n",
        "edge_weights = {\n",
        "    (1,2):1,(2,1):1,\n",
        "    (2,3):1,(3,2):1,\n",
        "    (3,4):1,(4,3):1,\n",
        "    (4,5):1,(5,4):1,\n",
        "    (5,1):1,(1,5):1\n",
        "}\n",
        "#- list edges = [(from_node_id,to_node_id)]\n",
        "edges = edge_weights.keys()\n",
        "#- dict node_featuress = {node_id:[r,g,b]}\n",
        "node_features = {\n",
        "    1:np.array([1,0,0]),\n",
        "    2:np.array([0,1,0]),\n",
        "    3:np.array([0,0,1]),\n",
        "    4:np.array([1,1,0]),\n",
        "    5:np.array([1,1,1])\n",
        "}\n",
        "#- dict node_degree_in = {node_id:int}\n",
        "#- dict node_degree_out = {node_id:int}\n",
        "node_degree_in = {}\n",
        "node_degree_out = {}\n",
        "for relation in edge_weights.keys():\n",
        "  if relation[0] in node_degree_out.keys():\n",
        "    node_degree_out[relation[0]] += 1\n",
        "  else:\n",
        "    node_degree_out[relation[0]] = 1\n",
        "  if relation[1] in node_degree_out.keys():\n",
        "    node_degree_in[relation[1]] += 1\n",
        "  else:\n",
        "    node_degree_in[relation[1]] = 1\n",
        "#- dict mask_label = {node_id:1/0}\n",
        "mask_lable = {\n",
        "    1:0,\n",
        "    2:1,\n",
        "    3:0,\n",
        "    4:1,\n",
        "    5:0\n",
        "}\n",
        "\n",
        "#####################################\n",
        "#vanilla label propagation\n",
        "epsilon = 0.01\n",
        "max_iter = 10000\n",
        "#function to calculate node feature differences\n",
        "def featureDiff(iter_features,curr_features,agg=max):\n",
        "  assert iter_features.keys() == curr_features.keys()\n",
        "  for node in iter_features.keys():\n",
        "    diff_dict[node] = agg(curr_features[node]-iter_features[node])\n",
        "  return diff_dict\n",
        "\n",
        "iter_features = node_features.copy()\n",
        "for i in range(max_iter):\n",
        "  curr_features = iter_features.copy()\n",
        "  #update label for masked nodes only\n",
        "  for relation in edge_weights.keys():\n",
        "    if mask_lable[relation[1]]:\n",
        "      curr_feature[relation[1]] += iter_feature[relation[0]]*edge_weights[relation]/len(node_degree_in[relation[1]])\n",
        "  #measure difference\n",
        "  errors = featureDiff(iter_features,curr_features)\n",
        "  iter_features = curr_features.copy()\n",
        "  if max(errors.values())<epsilon:\n",
        "    break\n",
        "\n",
        "#####################################\n",
        "#correct & smooth\n",
        "epsilon = 0.01\n",
        "max_iter = 10000\n",
        "alpha = 0.1\n",
        "diffusion_scale = 0.1\n",
        "#[ToDo]function to calculate diffusion matrix\n",
        "def adjDiffuse(adjacency):\n",
        "  diffusion = adjacency.copy()\n",
        "  return diffusion\n",
        "#[ToDo]function to calculate correction\n",
        "def correctStep(adjacency,errors,alpha,max_iter=max_iter,epsilon=epsilon,agg=max):\n",
        "  #[ToDo]dimension assersion\n",
        "  assert True\n",
        "  diffusion = adjDiffuse(adjacency)\n",
        "  e = errors.copy()\n",
        "  for i in range(max_iter):\n",
        "    curr_e = e.copy()\n",
        "    curr_e = (1-alpha)*e+alpha*diffusion.dot(e)\n",
        "    if agg(curr_e-e)<=epsilon:\n",
        "      break\n",
        "  return correction\n",
        "#[ToDo]function to do smooth step\n",
        "def smoothStep(adjacency,errors,alpha,max_iter=max_iter,epsilon=epsilon,agg=max):\n",
        "  #[ToDo]dimension assersion\n",
        "  assert True\n",
        "  diffusion = adjDiffuse(adjacency)\n",
        "  smooth = errors.copy()\n",
        "  for i in range(max_iter):\n",
        "    curr_z = z.copy()\n",
        "    curr_z = (1-alpha)*z+alpha*diffusion.dot(z)\n",
        "    if agg(curr_z-z)<=epsilon:\n",
        "      break\n",
        "  return smooth\n",
        "\n",
        "iter_features = node_features.copy()\n",
        "#[ToDo]correct step\n",
        "correction = correctStep()\n",
        "iter_features += diffusion_scale*correction\n",
        "#[ToDo]smooth step\n",
        "iter_features = smoothStep()\n"
      ],
      "metadata": {
        "id": "BApd6BS2gXj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
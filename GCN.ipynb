{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QQc4J2xsGWXQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSlw9GbyIcoD",
        "outputId": "e37af7c4-6e7b-4e99-f53e-f30560642576"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.13.1+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.17+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=6484a8c85cb283f258a87114165b9dd0c064eed58a63a4754f6d63bb23627f18\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.15)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.13.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (63.4.3)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=a82c6b35506e59864727c7f284136b9cc2dea43c6f964c7e6611441aea3b0660\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.5 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Process an image into PyG graph.\n",
        "# Each pixel is a node, and the edges are connections to 4-connectivity neighbors.\n",
        "def image_to_graph(image):\n",
        "    h, w = image.shape[:2]\n",
        "    num_nodes = h * w\n",
        "    edge_index = []\n",
        "\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            node_id = i * w + j\n",
        "            # Connect to the left pixel\n",
        "            if j > 0:\n",
        "              edge_index.append([node_id, node_id - 1])\n",
        "            # Connect to the right pixel\n",
        "            if j < w - 1:\n",
        "              edge_index.append([node_id, node_id + 1])\n",
        "            # Connect to the up pixel\n",
        "            if i > 0:\n",
        "              edge_index.append([node_id, node_id - w])\n",
        "            # Connect to the bottom pixel\n",
        "            if i < h - 1:\n",
        "              edge_index.append([node_id, node_id + w])\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    x = torch.tensor(image.reshape(-1, image.shape[-1]), dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# Process an image into PyG graph.\n",
        "# Each pixel is a node, and the edges are connections to neighbor pixels defined using `half_filter_dim`.\n",
        "# e.g `half_filter_dim` = 1, filter size is 3*3. `half_filter_dim` = 2, filter size is 5*5.\n",
        "def image_to_graph_with_filter(image, half_filter_dim):\n",
        "    h, w = image.shape[:2]\n",
        "    num_nodes = h * w\n",
        "    edge_index = []\n",
        "\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            node_id = i * w + j\n",
        "\n",
        "            for m in range(-half_filter_dim, half_filter_dim + 1):\n",
        "                for n in range(-half_filter_dim, half_filter_dim + 1):\n",
        "                    if m == 0 and n == 0:\n",
        "                        continue\n",
        "\n",
        "                    neighbor_i = i + m\n",
        "                    neighbor_j = j + n\n",
        "\n",
        "                    if (0 <= neighbor_i < h) and (0 <= neighbor_j < w):\n",
        "                        neighbor_id = neighbor_i * w + neighbor_j\n",
        "                        edge_index.append([node_id, neighbor_id])\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    x = torch.tensor(image.reshape(-1, image.shape[-1]), dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "def plotImg(image):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "z3FTNnvfGcsX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "image = np.random.rand(3, 3, 3)\n",
        "filter_dim = 1\n",
        "graph = image_to_graph_with_filter(image, filter_dim)\n",
        "graph.edge_index"
      ],
      "metadata": {
        "id": "lWLOhBfMLpXM"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class TwoLayerGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(TwoLayerGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, 3)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Convert labels to PyG graph format\n",
        "def labels_to_pyg_graph(labels):\n",
        "    return torch.tensor(labels.reshape(-1, labels.shape[-1]), dtype=torch.float)\n",
        "\n",
        "# Generate synthetic data for demonstration\n",
        "def generate_synthetic_data(num_images, img_size):\n",
        "    images = [np.random.rand(img_size, img_size, 3) for _ in range(num_images)]\n",
        "    labels = [np.random.rand(img_size, img_size, 3) for _ in range(num_images)]\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "bG3uLpUjZqf-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Parameters\n",
        "num_train_images = 100\n",
        "num_test_images = 20\n",
        "img_size = 5\n",
        "filter_dim = 1\n",
        "\n",
        "# Generate synthetic training and test data\n",
        "train_images, train_labels = generate_synthetic_data(num_train_images, img_size)\n",
        "test_images, test_labels = generate_synthetic_data(num_test_images, img_size)\n",
        "\n",
        "# Convert images and labels to PyG graphs\n",
        "train_graphs = [image_to_graph_with_filter(img, filter_dim) for img in train_images]\n",
        "test_graphs = [image_to_graph_with_filter(img, filter_dim) for img in test_images]\n",
        "\n",
        "train_labels = [labels_to_pyg_graph(lbl) for lbl in train_labels]\n",
        "test_labels = [labels_to_pyg_graph(lbl) for lbl in test_labels]\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(list(zip(train_graphs, train_labels)), batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(list(zip(test_graphs, test_labels)), batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = TwoLayerGCN(3, hidden_channels=16)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_fn(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Testing\n",
        "model.eval()\n",
        "mse_loss = 0\n",
        "with torch.no_grad():\n",
        "    for data, labels in test_loader:\n",
        "        out = model(data)\n",
        "        mse_loss += loss_fn(out, labels).item()\n",
        "\n",
        "print(f\"Node-level mean squared error: {mse_loss / len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g3QYEXOeQGa",
        "outputId": "f7aa362e-a05f-4963-c372-cd8caa88e862"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.11046109244227409\n",
            "Epoch 2/10, Loss: 0.08723216339945793\n",
            "Epoch 3/10, Loss: 0.08432250633835793\n",
            "Epoch 4/10, Loss: 0.08340477593243122\n",
            "Epoch 5/10, Loss: 0.08294453978538513\n",
            "Epoch 6/10, Loss: 0.08302599519491195\n",
            "Epoch 7/10, Loss: 0.08278303354978561\n",
            "Epoch 8/10, Loss: 0.08273020081222057\n",
            "Epoch 9/10, Loss: 0.08271180391311646\n",
            "Epoch 10/10, Loss: 0.08269989624619484\n",
            "Node-level mean squared error: 0.08439605236053467\n"
          ]
        }
      ]
    }
  ]
}
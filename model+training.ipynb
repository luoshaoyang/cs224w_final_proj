{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "mZKep_39CoFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "import cv2\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torch\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.utils import softmax\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "import glob\n",
        "from torch_geometric.data import Data, Dataset\n",
        "import pickle\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "UEAcgQFTByhB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "# Install torch geometric\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "id": "Yzvv3YRFB3Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "1cgK0DhZCr6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-r6eBRonBqH4"
      },
      "outputs": [],
      "source": [
        "class DiskGraphDataset(Dataset):\n",
        "    def __init__(self, root, file_name_wildcard, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.file_name_wildcard = root+file_name_wildcard\n",
        "        self.graph_filenames = glob.glob(self.file_name_wildcard)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.graph_filenames)\n",
        "\n",
        "    def get(self, idx):\n",
        "        # filename = self.file_name_wildcard.replace(\"*\", str(idx))\n",
        "        with open(self.graph_filenames[idx], 'rb') as f:\n",
        "            graph = pickle.load(f)\n",
        "        graph.y = labels_to_tensor(graph.y)\n",
        "        return graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "train_graphs = DiskGraphDataset(\"/content/drive/My Drive/Dataset/Graphs/wm-nowm/graphs_filter_3/\", \"train_graph_*.pkl\")\n",
        "test_graphs = DiskGraphDataset(\"/content/drive/My Drive/Dataset/Graphs/wm-nowm/graphs_filter_3/\", \"test_graph_*.pkl\")\n",
        "train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_graphs, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MH7EDOVCL7j",
        "outputId": "f7bca46c-bba2-41be-a1d1-6117ca2f23d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "n6q-L5WYCxa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom GATConv layer with separate message passing strategies for central and neighbor nodes\n",
        "class CustomGATConv(GATConv):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomGATConv, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "        attn_weight = torch.nn.functional.leaky_relu(alpha_j + alpha_i, negative_slope=0.2)\n",
        "        alpha = softmax(attn_weight, index, ptr, size_i)\n",
        "        alpha = torch.nn.functional.dropout(alpha, p=self.dropout, training=self.training)\n",
        "        out = x_j * alpha.unsqueeze(-1)\n",
        "        return out\n",
        "\n",
        "# Define the custom GAT model for node classification\n",
        "class CustomGAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels=16):\n",
        "        super(CustomGAT, self).__init__()\n",
        "        self.conv1 = GATConv(num_features, hidden_channels, 2, dropout=0.5)\n",
        "        self.conv2 = GATConv(32, 3, 1, concat=True, dropout=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        # x = x + data.x\n",
        "        return x\n",
        "\n",
        "class TwoLayerGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels):\n",
        "        super(TwoLayerGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, 3)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Convert labels to tensor\n",
        "def labels_to_tensor(labels):\n",
        "    return torch.tensor(labels.reshape(-1, labels.shape[-1]), dtype=torch.float)"
      ],
      "metadata": {
        "id": "ScTPqrrvCOLc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GCN Training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Initialize the model, loss function, and optimizer\n",
        "loss_fn_arg = \"BCE\"\n",
        "# model = TwoLayerGCN(3, hidden_channels=16)\n",
        "model = CustomGAT(3, hidden_channels=16).to(device)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "if loss_fn_arg == \"BCE\":\n",
        "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_fn(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "Y7kHbFrKDFOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "model.eval()\n",
        "loss = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        loss += loss_fn(out, data.y).item()\n",
        "\n",
        "print(f\"Node-level error: {loss / len(test_loader)}\")"
      ],
      "metadata": {
        "id": "p6lax5WpDLLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_graphs):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during inference\n",
        "        for graph in test_graphs:\n",
        "            # Convert node features and adjacency matrix to tensors if they are not already\n",
        "            # if not isinstance(node_features, torch.Tensor):\n",
        "            #     node_features = torch.tensor(node_features, dtype=torch.float32)\n",
        "            # if not isinstance(adjacency_matrix, torch.Tensor):\n",
        "            #     adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
        "\n",
        "            # # Move the tensors to the same device as the model\n",
        "            # node_features = node_features.to(model.device)\n",
        "            # adjacency_matrix = adjacency_matrix.to(model.device)\n",
        "\n",
        "            # Make predictions using the model\n",
        "            graph = graph.to(device)\n",
        "            output = model(graph)\n",
        "            predictions.append(output)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Use the 'predict' function to get predictions for the test_graphs\n",
        "test_predictions = predict(model, test_graphs)"
      ],
      "metadata": {
        "id": "g2TqWsyfDNw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 148 # only certain dimensions work due to UpSampling (196x196 works, 148x148 works)\n",
        "height = 148\n",
        "dim = (width, height) # set the dimensions\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(cv2.cvtColor(test_graphs[i].x.reshape(width,height,3).cpu().detach().numpy(), cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3pXliNTrDQwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(cv2.cvtColor(torch.sigmoid(test_predictions[i].reshape(width,height,3)).cpu().detach().numpy(), cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v4L54UqjDRLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}